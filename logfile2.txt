Script started on 2023-12-07 18:56:07+00:00 [TERM="xterm-256color" TTY="/dev/pts/0" COLUMNS="91" LINES="33"]
]0;paperspace@psybffhvzv5t: ~/Desktop/GenerativeImage2Text[01;32mpaperspace@psybffhvzv5t[00m:[01;34m~/Desktop/GenerativeImage2Text[00m$ script[Kscript logfile.txtcd ..[K[3P}"'prefix': '', \[12@model_name': 'GIT_BASE[C[C[C[C[KAZFUSE_TSV_USE_FUSE=1 python -m generativeimage2text.inference -p "{'type': 'test_git_inference_single_tsv', \
> 'image_tsv': 'data/coco_caption/test.img.tsv', \
> 'model_name': 'GIT_BASE_COCO', \
> 'question_tsv': null, \
> 'out_tsv': 'inference/GIT_BASE_COCO/coco.tsv', \
> }"
2023-12-07 18:57:10,076.076 6625:inference.py:318   <module>(): param:
{'image_tsv': 'data/coco_caption/test.img.tsv',
 'model_name': 'GIT_BASE_COCO',
 'out_tsv': 'inference/GIT_BASE_COCO/coco.tsv',
 'question_tsv': None,
 'type': 'test_git_inference_single_tsv'}
/home/paperspace/Desktop/GenerativeImage2Text/generativeimage2text/inference.py:119: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.
  Resize(crop_size, interpolation=Image.BICUBIC),
/home/paperspace/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-12-07 18:57:17,283.283 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.class_embedding                                         will be loaded from image_encoder.class_embedding                                         of shape (768,)
2023-12-07 18:57:17,283.283 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.conv1.weight                                            will be loaded from image_encoder.conv1.weight                                            of shape (768, 3, 16, 16)
2023-12-07 18:57:17,283.283 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.bias                                            will be loaded from image_encoder.ln_post.bias                                            of shape (768,)
2023-12-07 18:57:17,283.283 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.weight                                          will be loaded from image_encoder.ln_post.weight                                          of shape (768,)
2023-12-07 18:57:17,283.283 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.bias                                             will be loaded from image_encoder.ln_pre.bias                                             of shape (768,)
2023-12-07 18:57:17,283.283 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.weight                                           will be loaded from image_encoder.ln_pre.weight                                           of shape (768,)
2023-12-07 18:57:17,283.283 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.positional_embedding                                    will be loaded from image_encoder.positional_embedding                                    of shape (197, 768)
2023-12-07 18:57:17,283.283 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.proj                                                    will be loaded from image_encoder.proj                                                    of shape (768, 512)
2023-12-07 18:57:17,284.284 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:57:17,284.284 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:57:17,284.284 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.bias              of shape (768,)
2023-12-07 18:57:17,284.284 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:57:17,284.284 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_1.bias                       of shape (768,)
2023-12-07 18:57:17,284.284 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_1.weight                     of shape (768,)
2023-12-07 18:57:17,284.284 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_2.bias                       of shape (768,)
2023-12-07 18:57:17,284.284 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_2.weight                     of shape (768,)
2023-12-07 18:57:17,284.284 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:57:17,284.284 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:57:17,284.284 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:57:17,285.285 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:57:17,285.285 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:57:17,285.285 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:57:17,285.285 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.bias              of shape (768,)
2023-12-07 18:57:17,285.285 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:57:17,285.285 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_1.bias                       of shape (768,)
2023-12-07 18:57:17,285.285 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_1.weight                     of shape (768,)
2023-12-07 18:57:17,285.285 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_2.bias                       of shape (768,)
2023-12-07 18:57:17,285.285 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_2.weight                     of shape (768,)
2023-12-07 18:57:17,285.285 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:57:17,285.285 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:57:17,286.286 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:57:17,286.286 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:57:17,286.286 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_bias              of shape (2304,)
2023-12-07 18:57:17,286.286 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_weight            of shape (2304, 768)
2023-12-07 18:57:17,286.286 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.bias             of shape (768,)
2023-12-07 18:57:17,286.286 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.weight           of shape (768, 768)
2023-12-07 18:57:17,286.286 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_1.bias                      of shape (768,)
2023-12-07 18:57:17,286.286 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_1.weight                    of shape (768,)
2023-12-07 18:57:17,286.286 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_2.bias                      of shape (768,)
2023-12-07 18:57:17,287.287 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_2.weight                    of shape (768,)
2023-12-07 18:57:17,287.287 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  of shape (3072,)
2023-12-07 18:57:17,287.287 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.weight                of shape (3072, 768)
2023-12-07 18:57:17,287.287 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.bias                of shape (768,)
2023-12-07 18:57:17,287.287 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.weight              of shape (768, 3072)
2023-12-07 18:57:17,287.287 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_bias              of shape (2304,)
2023-12-07 18:57:17,287.287 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_weight            of shape (2304, 768)
2023-12-07 18:57:17,287.287 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.bias             of shape (768,)
2023-12-07 18:57:17,287.287 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.weight           of shape (768, 768)
2023-12-07 18:57:17,287.287 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_1.bias                      of shape (768,)
2023-12-07 18:57:17,288.288 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_1.weight                    of shape (768,)
2023-12-07 18:57:17,288.288 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_2.bias                      of shape (768,)
2023-12-07 18:57:17,288.288 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_2.weight                    of shape (768,)
2023-12-07 18:57:17,288.288 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  of shape (3072,)
2023-12-07 18:57:17,288.288 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.weight                of shape (3072, 768)
2023-12-07 18:57:17,288.288 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.bias                of shape (768,)
2023-12-07 18:57:17,288.288 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.weight              of shape (768, 3072)
2023-12-07 18:57:17,288.288 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:57:17,288.288 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:57:17,288.288 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.bias              of shape (768,)
2023-12-07 18:57:17,288.288 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:57:17,289.289 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_1.bias                       of shape (768,)
2023-12-07 18:57:17,289.289 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_1.weight                     of shape (768,)
2023-12-07 18:57:17,289.289 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_2.bias                       of shape (768,)
2023-12-07 18:57:17,289.289 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_2.weight                     of shape (768,)
2023-12-07 18:57:17,289.289 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:57:17,289.289 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:57:17,289.289 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:57:17,289.289 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:57:17,289.289 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:57:17,289.289 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:57:17,289.289 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.bias              of shape (768,)
2023-12-07 18:57:17,289.289 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:57:17,290.290 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_1.bias                       of shape (768,)
2023-12-07 18:57:17,290.290 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_1.weight                     of shape (768,)
2023-12-07 18:57:17,290.290 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_2.bias                       of shape (768,)
2023-12-07 18:57:17,290.290 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_2.weight                     of shape (768,)
2023-12-07 18:57:17,290.290 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:57:17,290.290 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:57:17,290.290 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:57:17,290.290 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:57:17,290.290 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:57:17,290.290 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:57:17,290.290 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.bias              of shape (768,)
2023-12-07 18:57:17,290.290 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:57:17,290.290 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_1.bias                       of shape (768,)
2023-12-07 18:57:17,290.290 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_1.weight                     of shape (768,)
2023-12-07 18:57:17,291.291 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_2.bias                       of shape (768,)
2023-12-07 18:57:17,291.291 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_2.weight                     of shape (768,)
2023-12-07 18:57:17,291.291 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:57:17,291.291 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:57:17,291.291 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:57:17,291.291 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:57:17,291.291 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:57:17,291.291 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:57:17,291.291 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.bias              of shape (768,)
2023-12-07 18:57:17,291.291 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:57:17,291.291 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_1.bias                       of shape (768,)
2023-12-07 18:57:17,292.292 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_1.weight                     of shape (768,)
2023-12-07 18:57:17,292.292 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_2.bias                       of shape (768,)
2023-12-07 18:57:17,292.292 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_2.weight                     of shape (768,)
2023-12-07 18:57:17,292.292 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:57:17,292.292 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:57:17,292.292 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:57:17,292.292 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:57:17,292.292 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:57:17,292.292 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:57:17,292.292 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.bias              of shape (768,)
2023-12-07 18:57:17,293.293 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:57:17,293.293 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_1.bias                       of shape (768,)
2023-12-07 18:57:17,293.293 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_1.weight                     of shape (768,)
2023-12-07 18:57:17,293.293 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_2.bias                       of shape (768,)
2023-12-07 18:57:17,293.293 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_2.weight                     of shape (768,)
2023-12-07 18:57:17,293.293 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:57:17,293.293 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:57:17,293.293 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:57:17,293.293 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:57:17,294.294 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:57:17,294.294 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:57:17,294.294 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.bias              of shape (768,)
2023-12-07 18:57:17,294.294 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:57:17,294.294 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_1.bias                       of shape (768,)
2023-12-07 18:57:17,294.294 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_1.weight                     of shape (768,)
2023-12-07 18:57:17,294.294 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_2.bias                       of shape (768,)
2023-12-07 18:57:17,294.294 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_2.weight                     of shape (768,)
2023-12-07 18:57:17,294.294 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:57:17,294.294 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:57:17,294.294 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:57:17,294.294 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:57:17,295.295 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:57:17,295.295 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:57:17,295.295 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.bias              of shape (768,)
2023-12-07 18:57:17,295.295 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:57:17,295.295 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_1.bias                       of shape (768,)
2023-12-07 18:57:17,295.295 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_1.weight                     of shape (768,)
2023-12-07 18:57:17,295.295 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_2.bias                       of shape (768,)
2023-12-07 18:57:17,295.295 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_2.weight                     of shape (768,)
2023-12-07 18:57:17,295.295 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:57:17,295.295 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:57:17,295.295 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:57:17,295.295 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:57:17,295.295 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:57:17,295.295 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:57:17,296.296 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.bias              of shape (768,)
2023-12-07 18:57:17,296.296 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:57:17,296.296 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_1.bias                       of shape (768,)
2023-12-07 18:57:17,296.296 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_1.weight                     of shape (768,)
2023-12-07 18:57:17,296.296 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_2.bias                       of shape (768,)
2023-12-07 18:57:17,296.296 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_2.weight                     of shape (768,)
2023-12-07 18:57:17,296.296 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:57:17,296.296 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:57:17,296.296 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:57:17,296.296 6625:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:57:17,296.296 6625:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.bias                                     will be loaded from textual.embedding.layer_norm.bias                                     of shape (768,)
2023-12-07 18:57:17,296.296 6625:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.weight                                   will be loaded from textual.embedding.layer_norm.weight                                   of shape (768,)
2023-12-07 18:57:17,296.296 6625:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.positions.weight                                    will be loaded from textual.embedding.positions.weight                                    of shape (1024, 768)
2023-12-07 18:57:17,296.296 6625:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.words.weight                                        will be loaded from textual.embedding.words.weight                                        of shape (30522, 768)
2023-12-07 18:57:17,296.296 6625:torch_common.py:128 align_and_update_state_dicts(): textual.output.bias                                                   will be loaded from textual.output.bias                                                   of shape (30522,)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.output.weight                                                 will be loaded from textual.output.weight                                                 of shape (30522, 768)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   of shape (768,)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight of shape (768,)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.bias       of shape (768,)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.weight     of shape (768, 768)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.0.attention.self.key.bias           of shape (768,)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.0.attention.self.key.weight         of shape (768, 768)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.query.bias         of shape (768,)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.query.weight       of shape (768, 768)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.value.bias         of shape (768,)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.value.weight       of shape (768, 768)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.bias           of shape (3072,)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.weight         of shape (3072, 768)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.bias             of shape (768,)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.weight           of shape (768,)
2023-12-07 18:57:17,297.297 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.0.output.dense.bias                 of shape (768,)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.weight               will be loaded from textual.transformer.encoder.layer.0.output.dense.weight               of shape (768, 3072)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   of shape (768,)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight of shape (768,)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.bias       of shape (768,)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.weight     of shape (768, 768)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.1.attention.self.key.bias           of shape (768,)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.1.attention.self.key.weight         of shape (768, 768)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.query.bias         of shape (768,)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.query.weight       of shape (768, 768)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.value.bias         of shape (768,)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.value.weight       of shape (768, 768)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.bias           of shape (3072,)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.weight         of shape (3072, 768)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.bias             of shape (768,)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.weight           of shape (768,)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.1.output.dense.bias                 of shape (768,)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.weight               will be loaded from textual.transformer.encoder.layer.1.output.dense.weight               of shape (768, 3072)
2023-12-07 18:57:17,298.298 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   of shape (768,)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight of shape (768,)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.bias       of shape (768,)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.weight     of shape (768, 768)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.2.attention.self.key.bias           of shape (768,)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.2.attention.self.key.weight         of shape (768, 768)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.query.bias         of shape (768,)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.query.weight       of shape (768, 768)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.value.bias         of shape (768,)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.value.weight       of shape (768, 768)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.bias           of shape (3072,)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.weight         of shape (3072, 768)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.bias             of shape (768,)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.weight           of shape (768,)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.2.output.dense.bias                 of shape (768,)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.weight               will be loaded from textual.transformer.encoder.layer.2.output.dense.weight               of shape (768, 3072)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   of shape (768,)
2023-12-07 18:57:17,299.299 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight of shape (768,)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.bias       of shape (768,)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.weight     of shape (768, 768)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.3.attention.self.key.bias           of shape (768,)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.3.attention.self.key.weight         of shape (768, 768)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.query.bias         of shape (768,)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.query.weight       of shape (768, 768)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.value.bias         of shape (768,)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.value.weight       of shape (768, 768)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.bias           of shape (3072,)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.weight         of shape (3072, 768)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.bias             of shape (768,)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.weight           of shape (768,)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.3.output.dense.bias                 of shape (768,)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.weight               will be loaded from textual.transformer.encoder.layer.3.output.dense.weight               of shape (768, 3072)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   of shape (768,)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight of shape (768,)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.bias       of shape (768,)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.weight     of shape (768, 768)
2023-12-07 18:57:17,300.300 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.4.attention.self.key.bias           of shape (768,)
2023-12-07 18:57:17,301.301 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.4.attention.self.key.weight         of shape (768, 768)
2023-12-07 18:57:17,301.301 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.query.bias         of shape (768,)
2023-12-07 18:57:17,301.301 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.query.weight       of shape (768, 768)
2023-12-07 18:57:17,301.301 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.value.bias         of shape (768,)
2023-12-07 18:57:17,301.301 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.value.weight       of shape (768, 768)
2023-12-07 18:57:17,301.301 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.bias           of shape (3072,)
2023-12-07 18:57:17,301.301 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.weight         of shape (3072, 768)
2023-12-07 18:57:17,301.301 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.bias             of shape (768,)
2023-12-07 18:57:17,301.301 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.weight           of shape (768,)
2023-12-07 18:57:17,301.301 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.4.output.dense.bias                 of shape (768,)
2023-12-07 18:57:17,301.301 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.weight               will be loaded from textual.transformer.encoder.layer.4.output.dense.weight               of shape (768, 3072)
2023-12-07 18:57:17,301.301 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   of shape (768,)
2023-12-07 18:57:17,301.301 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight of shape (768,)
2023-12-07 18:57:17,301.301 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.bias       of shape (768,)
2023-12-07 18:57:17,302.302 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.weight     of shape (768, 768)
2023-12-07 18:57:17,302.302 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.5.attention.self.key.bias           of shape (768,)
2023-12-07 18:57:17,302.302 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.5.attention.self.key.weight         of shape (768, 768)
2023-12-07 18:57:17,302.302 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.query.bias         of shape (768,)
2023-12-07 18:57:17,302.302 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.query.weight       of shape (768, 768)
2023-12-07 18:57:17,302.302 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.value.bias         of shape (768,)
2023-12-07 18:57:17,302.302 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.value.weight       of shape (768, 768)
2023-12-07 18:57:17,302.302 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.bias           of shape (3072,)
2023-12-07 18:57:17,302.302 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.weight         of shape (3072, 768)
2023-12-07 18:57:17,302.302 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.bias             of shape (768,)
2023-12-07 18:57:17,303.303 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.weight           of shape (768,)
2023-12-07 18:57:17,303.303 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.5.output.dense.bias                 of shape (768,)
2023-12-07 18:57:17,303.303 6625:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.weight               will be loaded from textual.transformer.encoder.layer.5.output.dense.weight               of shape (768, 3072)
2023-12-07 18:57:17,303.303 6625:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.bias                                      will be loaded from textual.visual_projection.0.bias                                      of shape (768,)
2023-12-07 18:57:17,303.303 6625:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.weight                                    will be loaded from textual.visual_projection.0.weight                                    of shape (768, 768)
2023-12-07 18:57:17,303.303 6625:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.bias                                      will be loaded from textual.visual_projection.1.bias                                      of shape (768,)
2023-12-07 18:57:17,303.303 6625:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.weight                                    will be loaded from textual.visual_projection.1.weight                                    of shape (768,)
2023-12-07 18:57:17,303.303 6625:torch_common.py:137 align_and_update_state_dicts(): target model param = 258; name matched = 258; loaded = 258
2023-12-07 18:57:17,303.303 6625:torch_common.py:140 align_and_update_state_dicts(): from loaded; ignore = []
2023-12-07 18:57:17,306.306 6625:torch_common.py:82 load_model_state_ignore_mismatch(): unique keys in init dict = ['textual.output.weight']; total = 1
2023-12-07 18:57:17,384.384 6625:torch_common.py:86 load_model_state_ignore_mismatch(): unique key (not initialized) in current model = ['textual.output.weight']
tsv_io.py:363: 0it [00:00, ?it/s]
inference.py:202:   0%|                                           | 0/5000 [00:00<?, ?it/s][A/home/paperspace/Desktop/GenerativeImage2Text/generativeimage2text/layers/decoder.py:1198: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beam_id = idx // vocab_size
tsv_io.py:363: 1it [00:08,  8.22s/it]
inference.py:202:   0%|                                | 1/5000 [00:08<11:24:57,  8.22s/it][Ainference.py:202:   0%|                                | 1/5000 [00:08<12:17:39,  8.85s/it]
tsv_io.py:363: 1it [00:08,  8.85s/it]
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/paperspace/Desktop/GenerativeImage2Text/generativeimage2text/inference.py", line 321, in <module>
    locals()[function_name](**kwargs)
  File "/home/paperspace/Desktop/GenerativeImage2Text/generativeimage2text/inference.py", line 213, in test_git_inference_single_tsv
    tsv_writer(gen_rows(), curr_out_tsv)
  File "/home/paperspace/Desktop/GenerativeImage2Text/generativeimage2text/tsv_io.py", line 363, in tsv_writer
    for value in tqdm(values):
  File "/home/paperspace/.local/lib/python3.9/site-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/home/paperspace/Desktop/GenerativeImage2Text/generativeimage2text/inference.py", line 206, in gen_rows
    img = img.cuda().unsqueeze(0)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
]0;paperspace@psybffhvzv5t: ~/Desktop/GenerativeImage2Text[01;32mpaperspace@psybffhvzv5t[00m:[01;34m~/Desktop/GenerativeImage2Text[00m$ clear
[H[2J[3J]0;paperspace@psybffhvzv5t: ~/Desktop/GenerativeImage2Text[01;32mpaperspace@psybffhvzv5t[00m:[01;34m~/Desktop/GenerativeImage2Text[00m$ AZFUSE_TSV_USE_FUSE=1 python -m generativeimage2text.inference -p "{'type': 'test_git_inference_single_tsv', \
> 'image_tsv': 'data/coco_caption/test.img.tsv', \
> 'model_name': 'GIT_BASE_COCO', \
> 'question_tsv': null, \
> 'out_tsv': 'inference/GIT_BASE_COCO/coco.tsv', \
> }"
2023-12-07 18:58:37,678.678 7098:inference.py:318   <module>(): param:
{'image_tsv': 'data/coco_caption/test.img.tsv',
 'model_name': 'GIT_BASE_COCO',
 'out_tsv': 'inference/GIT_BASE_COCO/coco.tsv',
 'question_tsv': None,
 'type': 'test_git_inference_single_tsv'}
/home/paperspace/Desktop/GenerativeImage2Text/generativeimage2text/inference.py:119: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.
  Resize(crop_size, interpolation=Image.BICUBIC),
/home/paperspace/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-12-07 18:58:45,152.152 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.class_embedding                                         will be loaded from image_encoder.class_embedding                                         of shape (768,)
2023-12-07 18:58:45,152.152 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.conv1.weight                                            will be loaded from image_encoder.conv1.weight                                            of shape (768, 3, 16, 16)
2023-12-07 18:58:45,152.152 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.bias                                            will be loaded from image_encoder.ln_post.bias                                            of shape (768,)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.weight                                          will be loaded from image_encoder.ln_post.weight                                          of shape (768,)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.bias                                             will be loaded from image_encoder.ln_pre.bias                                             of shape (768,)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.weight                                           will be loaded from image_encoder.ln_pre.weight                                           of shape (768,)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.positional_embedding                                    will be loaded from image_encoder.positional_embedding                                    of shape (197, 768)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.proj                                                    will be loaded from image_encoder.proj                                                    of shape (768, 512)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.bias              of shape (768,)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_1.bias                       of shape (768,)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_1.weight                     of shape (768,)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_2.bias                       of shape (768,)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_2.weight                     of shape (768,)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:58:45,153.153 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:58:45,154.154 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:58:45,154.154 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:58:45,154.154 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:58:45,154.154 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.bias              of shape (768,)
2023-12-07 18:58:45,154.154 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:58:45,154.154 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_1.bias                       of shape (768,)
2023-12-07 18:58:45,154.154 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_1.weight                     of shape (768,)
2023-12-07 18:58:45,154.154 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_2.bias                       of shape (768,)
2023-12-07 18:58:45,154.154 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_2.weight                     of shape (768,)
2023-12-07 18:58:45,154.154 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:58:45,154.154 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:58:45,154.154 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:58:45,154.154 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:58:45,154.154 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_bias              of shape (2304,)
2023-12-07 18:58:45,155.155 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_weight            of shape (2304, 768)
2023-12-07 18:58:45,155.155 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.bias             of shape (768,)
2023-12-07 18:58:45,155.155 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.weight           of shape (768, 768)
2023-12-07 18:58:45,155.155 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_1.bias                      of shape (768,)
2023-12-07 18:58:45,155.155 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_1.weight                    of shape (768,)
2023-12-07 18:58:45,155.155 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_2.bias                      of shape (768,)
2023-12-07 18:58:45,155.155 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_2.weight                    of shape (768,)
2023-12-07 18:58:45,155.155 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  of shape (3072,)
2023-12-07 18:58:45,155.155 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.weight                of shape (3072, 768)
2023-12-07 18:58:45,155.155 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.bias                of shape (768,)
2023-12-07 18:58:45,156.156 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.weight              of shape (768, 3072)
2023-12-07 18:58:45,156.156 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_bias              of shape (2304,)
2023-12-07 18:58:45,156.156 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_weight            of shape (2304, 768)
2023-12-07 18:58:45,156.156 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.bias             of shape (768,)
2023-12-07 18:58:45,156.156 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.weight           of shape (768, 768)
2023-12-07 18:58:45,156.156 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_1.bias                      of shape (768,)
2023-12-07 18:58:45,156.156 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_1.weight                    of shape (768,)
2023-12-07 18:58:45,156.156 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_2.bias                      of shape (768,)
2023-12-07 18:58:45,156.156 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_2.weight                    of shape (768,)
2023-12-07 18:58:45,156.156 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  of shape (3072,)
2023-12-07 18:58:45,157.157 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.weight                of shape (3072, 768)
2023-12-07 18:58:45,157.157 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.bias                of shape (768,)
2023-12-07 18:58:45,157.157 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.weight              of shape (768, 3072)
2023-12-07 18:58:45,157.157 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:58:45,157.157 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:58:45,157.157 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.bias              of shape (768,)
2023-12-07 18:58:45,157.157 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:58:45,157.157 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_1.bias                       of shape (768,)
2023-12-07 18:58:45,157.157 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_1.weight                     of shape (768,)
2023-12-07 18:58:45,157.157 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_2.bias                       of shape (768,)
2023-12-07 18:58:45,157.157 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_2.weight                     of shape (768,)
2023-12-07 18:58:45,157.157 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:58:45,157.157 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:58:45,157.157 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.bias              of shape (768,)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_1.bias                       of shape (768,)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_1.weight                     of shape (768,)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_2.bias                       of shape (768,)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_2.weight                     of shape (768,)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.bias              of shape (768,)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:58:45,158.158 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_1.bias                       of shape (768,)
2023-12-07 18:58:45,159.159 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_1.weight                     of shape (768,)
2023-12-07 18:58:45,159.159 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_2.bias                       of shape (768,)
2023-12-07 18:58:45,159.159 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_2.weight                     of shape (768,)
2023-12-07 18:58:45,159.159 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:58:45,159.159 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:58:45,159.159 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:58:45,159.159 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:58:45,159.159 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:58:45,159.159 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:58:45,159.159 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.bias              of shape (768,)
2023-12-07 18:58:45,159.159 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:58:45,159.159 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_1.bias                       of shape (768,)
2023-12-07 18:58:45,159.159 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_1.weight                     of shape (768,)
2023-12-07 18:58:45,159.159 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_2.bias                       of shape (768,)
2023-12-07 18:58:45,160.160 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_2.weight                     of shape (768,)
2023-12-07 18:58:45,160.160 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:58:45,160.160 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:58:45,160.160 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:58:45,160.160 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:58:45,160.160 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:58:45,160.160 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:58:45,160.160 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.bias              of shape (768,)
2023-12-07 18:58:45,160.160 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:58:45,160.160 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_1.bias                       of shape (768,)
2023-12-07 18:58:45,160.160 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_1.weight                     of shape (768,)
2023-12-07 18:58:45,160.160 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_2.bias                       of shape (768,)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_2.weight                     of shape (768,)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.bias              of shape (768,)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_1.bias                       of shape (768,)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_1.weight                     of shape (768,)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_2.bias                       of shape (768,)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_2.weight                     of shape (768,)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:58:45,161.161 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.bias              of shape (768,)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_1.bias                       of shape (768,)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_1.weight                     of shape (768,)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_2.bias                       of shape (768,)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_2.weight                     of shape (768,)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_bias               of shape (2304,)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_weight             of shape (2304, 768)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.bias              of shape (768,)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.weight            of shape (768, 768)
2023-12-07 18:58:45,162.162 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_1.bias                       of shape (768,)
2023-12-07 18:58:45,163.163 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_1.weight                     of shape (768,)
2023-12-07 18:58:45,163.163 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_2.bias                       of shape (768,)
2023-12-07 18:58:45,163.163 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_2.weight                     of shape (768,)
2023-12-07 18:58:45,163.163 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   of shape (3072,)
2023-12-07 18:58:45,163.163 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 of shape (3072, 768)
2023-12-07 18:58:45,163.163 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 of shape (768,)
2023-12-07 18:58:45,163.163 7098:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.weight               of shape (768, 3072)
2023-12-07 18:58:45,163.163 7098:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.bias                                     will be loaded from textual.embedding.layer_norm.bias                                     of shape (768,)
2023-12-07 18:58:45,163.163 7098:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.weight                                   will be loaded from textual.embedding.layer_norm.weight                                   of shape (768,)
2023-12-07 18:58:45,163.163 7098:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.positions.weight                                    will be loaded from textual.embedding.positions.weight                                    of shape (1024, 768)
2023-12-07 18:58:45,163.163 7098:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.words.weight                                        will be loaded from textual.embedding.words.weight                                        of shape (30522, 768)
2023-12-07 18:58:45,163.163 7098:torch_common.py:128 align_and_update_state_dicts(): textual.output.bias                                                   will be loaded from textual.output.bias                                                   of shape (30522,)
2023-12-07 18:58:45,163.163 7098:torch_common.py:128 align_and_update_state_dicts(): textual.output.weight                                                 will be loaded from textual.output.weight                                                 of shape (30522, 768)
2023-12-07 18:58:45,163.163 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   of shape (768,)
2023-12-07 18:58:45,163.163 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight of shape (768,)
2023-12-07 18:58:45,164.164 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.bias       of shape (768,)
2023-12-07 18:58:45,164.164 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.weight     of shape (768, 768)
2023-12-07 18:58:45,164.164 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.0.attention.self.key.bias           of shape (768,)
2023-12-07 18:58:45,164.164 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.0.attention.self.key.weight         of shape (768, 768)
2023-12-07 18:58:45,164.164 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.query.bias         of shape (768,)
2023-12-07 18:58:45,164.164 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.query.weight       of shape (768, 768)
2023-12-07 18:58:45,164.164 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.value.bias         of shape (768,)
2023-12-07 18:58:45,164.164 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.value.weight       of shape (768, 768)
2023-12-07 18:58:45,164.164 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.bias           of shape (3072,)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.weight         of shape (3072, 768)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.bias             of shape (768,)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.weight           of shape (768,)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.0.output.dense.bias                 of shape (768,)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.weight               will be loaded from textual.transformer.encoder.layer.0.output.dense.weight               of shape (768, 3072)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   of shape (768,)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight of shape (768,)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.bias       of shape (768,)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.weight     of shape (768, 768)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.1.attention.self.key.bias           of shape (768,)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.1.attention.self.key.weight         of shape (768, 768)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.query.bias         of shape (768,)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.query.weight       of shape (768, 768)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.value.bias         of shape (768,)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.value.weight       of shape (768, 768)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.bias           of shape (3072,)
2023-12-07 18:58:45,165.165 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.weight         of shape (3072, 768)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.bias             of shape (768,)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.weight           of shape (768,)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.1.output.dense.bias                 of shape (768,)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.weight               will be loaded from textual.transformer.encoder.layer.1.output.dense.weight               of shape (768, 3072)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   of shape (768,)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight of shape (768,)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.bias       of shape (768,)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.weight     of shape (768, 768)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.2.attention.self.key.bias           of shape (768,)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.2.attention.self.key.weight         of shape (768, 768)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.query.bias         of shape (768,)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.query.weight       of shape (768, 768)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.value.bias         of shape (768,)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.value.weight       of shape (768, 768)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.bias           of shape (3072,)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.weight         of shape (3072, 768)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.bias             of shape (768,)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.weight           of shape (768,)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.2.output.dense.bias                 of shape (768,)
2023-12-07 18:58:45,166.166 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.weight               will be loaded from textual.transformer.encoder.layer.2.output.dense.weight               of shape (768, 3072)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   of shape (768,)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight of shape (768,)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.bias       of shape (768,)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.weight     of shape (768, 768)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.3.attention.self.key.bias           of shape (768,)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.3.attention.self.key.weight         of shape (768, 768)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.query.bias         of shape (768,)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.query.weight       of shape (768, 768)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.value.bias         of shape (768,)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.value.weight       of shape (768, 768)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.bias           of shape (3072,)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.weight         of shape (3072, 768)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.bias             of shape (768,)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.weight           of shape (768,)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.3.output.dense.bias                 of shape (768,)
2023-12-07 18:58:45,167.167 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.weight               will be loaded from textual.transformer.encoder.layer.3.output.dense.weight               of shape (768, 3072)
2023-12-07 18:58:45,168.168 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   of shape (768,)
2023-12-07 18:58:45,168.168 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight of shape (768,)
2023-12-07 18:58:45,168.168 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.bias       of shape (768,)
2023-12-07 18:58:45,168.168 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.weight     of shape (768, 768)
2023-12-07 18:58:45,168.168 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.4.attention.self.key.bias           of shape (768,)
2023-12-07 18:58:45,168.168 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.4.attention.self.key.weight         of shape (768, 768)
2023-12-07 18:58:45,168.168 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.query.bias         of shape (768,)
2023-12-07 18:58:45,168.168 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.query.weight       of shape (768, 768)
2023-12-07 18:58:45,168.168 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.value.bias         of shape (768,)
2023-12-07 18:58:45,168.168 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.value.weight       of shape (768, 768)
2023-12-07 18:58:45,168.168 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.bias           of shape (3072,)
2023-12-07 18:58:45,168.168 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.weight         of shape (3072, 768)
2023-12-07 18:58:45,168.168 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.bias             of shape (768,)
2023-12-07 18:58:45,168.168 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.weight           of shape (768,)
2023-12-07 18:58:45,169.169 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.4.output.dense.bias                 of shape (768,)
2023-12-07 18:58:45,169.169 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.weight               will be loaded from textual.transformer.encoder.layer.4.output.dense.weight               of shape (768, 3072)
2023-12-07 18:58:45,169.169 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   of shape (768,)
2023-12-07 18:58:45,169.169 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight of shape (768,)
2023-12-07 18:58:45,169.169 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.bias       of shape (768,)
2023-12-07 18:58:45,169.169 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.weight     of shape (768, 768)
2023-12-07 18:58:45,169.169 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.5.attention.self.key.bias           of shape (768,)
2023-12-07 18:58:45,169.169 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.5.attention.self.key.weight         of shape (768, 768)
2023-12-07 18:58:45,169.169 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.query.bias         of shape (768,)
2023-12-07 18:58:45,169.169 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.query.weight       of shape (768, 768)
2023-12-07 18:58:45,169.169 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.value.bias         of shape (768,)
2023-12-07 18:58:45,169.169 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.value.weight       of shape (768, 768)
2023-12-07 18:58:45,169.169 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.bias           of shape (3072,)
2023-12-07 18:58:45,169.169 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.weight         of shape (3072, 768)
2023-12-07 18:58:45,169.169 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.bias             of shape (768,)
2023-12-07 18:58:45,170.170 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.weight           of shape (768,)
2023-12-07 18:58:45,170.170 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.5.output.dense.bias                 of shape (768,)
2023-12-07 18:58:45,170.170 7098:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.weight               will be loaded from textual.transformer.encoder.layer.5.output.dense.weight               of shape (768, 3072)
2023-12-07 18:58:45,170.170 7098:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.bias                                      will be loaded from textual.visual_projection.0.bias                                      of shape (768,)
2023-12-07 18:58:45,170.170 7098:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.weight                                    will be loaded from textual.visual_projection.0.weight                                    of shape (768, 768)
2023-12-07 18:58:45,170.170 7098:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.bias                                      will be loaded from textual.visual_projection.1.bias                                      of shape (768,)
2023-12-07 18:58:45,170.170 7098:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.weight                                    will be loaded from textual.visual_projection.1.weight                                    of shape (768,)
2023-12-07 18:58:45,170.170 7098:torch_common.py:137 align_and_update_state_dicts(): target model param = 258; name matched = 258; loaded = 258
2023-12-07 18:58:45,170.170 7098:torch_common.py:140 align_and_update_state_dicts(): from loaded; ignore = []
2023-12-07 18:58:45,174.174 7098:torch_common.py:82 load_model_state_ignore_mismatch(): unique keys in init dict = ['textual.output.weight']; total = 1
2023-12-07 18:58:45,296.296 7098:torch_common.py:86 load_model_state_ignore_mismatch(): unique key (not initialized) in current model = ['textual.output.weight']
tsv_io.py:363: 0it [00:00, ?it/s]
inference.py:202:   0%|                                           | 0/5000 [00:00<?, ?it/s][A/home/paperspace/Desktop/GenerativeImage2Text/generativeimage2text/layers/decoder.py:1198: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beam_id = idx // vocab_size
tsv_io.py:363: 1it [00:08,  8.12s/it]
inference.py:202:   0%|                                | 1/5000 [00:08<11:16:28,  8.12s/it][Ainference.py:202:   0%|                                | 1/5000 [00:08<12:04:21,  8.69s/it]
tsv_io.py:363: 1it [00:08,  8.70s/it]
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/h